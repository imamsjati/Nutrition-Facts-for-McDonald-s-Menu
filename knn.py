# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eCRvY-PKERr-M-j7xQlBaBY1079XSdY6

## **DTS Data Science**
# Institut Teknologi Sepuluh Nopember (Kelas B)

## **CHALLENGE 3**

## **Nutrition Facts for McDonald's Menu**

**Introduction**

Ray Kroc wanted to build a restaurant system that would be famous for providing food of cosistently high quality and uniform methods of preparation. He wanted to serve burgers, buns, fries and beverages that tasted just the same in Alaska as they did in Alabama. To achieve this, he chose a unique path: persuading both franchisees and suppliers to buy into his vision, working not for McDonald's but for themselves, together with McDonald's. Many of McDonald's most famous menu item's - Like Big Mac, Filet-O-Fish, and Egg McMuffin were created by franchisees

**Nutrition Facts for McDonald's Menu Dataset** provides a nutrition analysis of every menu item on the US McDonald's menu, including breakfast, beef burgers, chicken and fish sandwiches, fries, salads, soda, coffee and tea, milkshakes, and desserts.



# Klasifikasi menggunakan K-Neirst Neighbor
"""

# Commented out IPython magic to ensure Python compatibility.
import itertools
import numpy as np
from matplotlib.ticker import NullFormatter
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
# %matplotlib inline
import pandas as pd
import numpy as np
from sklearn import preprocessing

"""Membaca Data"""

from google.colab import files
data_to_load = files.upload()

import io
df = pd.read_csv(io.BytesIO(data_to_load['menu.csv']))
df

"""Pelabelan berdasarkan Category"""

df['Category'].value_counts()

"""Didapati bahwa:
Category             Jumlah Data
Coffee & Tea          95
Breakfast             42
Smoothies & Shakes    28
Chicken & Fish        27
Beverages             27
Beef & Pork           15
Snacks & Sides        13
Desserts               7
Salads                 6

Histogram sebaran data Carbohydrates
"""

df.hist(column='Carbohydrates', bins=50)

"""Pemilihan feature set"""

df.columns

"""Feature yang dipilih ['Calories', 'Calories from Fat','Total Fat', 'Total Fat (% Daily Value)', 'Saturated Fat','Saturated Fat (% Daily Value)', 'Trans Fat', 'Cholesterol','Cholesterol (% Daily Value)', 'Sodium', 'Sodium (% Daily Value)','Carbohydrates', 'Carbohydrates (% Daily Value)', 'Dietary Fiber','Dietary Fiber (% Daily Value)', 'Sugars', 'Protein','Vitamin A (% Daily Value)', 'Vitamin C (% Daily Value)','Calcium (% Daily Value)', 'Iron (% Daily Value)']

Konversi Pandas Data frame ke array numpy agar bisa digunakan di scikit-learn library
"""

X = df[['Calories', 'Calories_from_Fat','Total_Fat', 'Total Fat (% Daily Value)', 'Saturated Fat','Saturated Fat (% Daily Value)', 'Trans Fat', 'Cholesterol','Cholesterol (% Daily Value)', 'Sodium', 'Sodium (% Daily Value)','Carbohydrates', 'Carbohydrates (% Daily Value)', 'Dietary Fiber','Dietary Fiber (% Daily Value)', 'Sugars', 'Protein','Vitamin A (% Daily Value)', 'Vitamin C (% Daily Value)','Calcium (% Daily Value)', 'Iron (% Daily Value)']] .values #astype(float)
X[0:5]

y = df['Category'].values
y[0:5]

"""Normalisasi Data"""

X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))
X[0:5]

"""Train test split"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)
print ('Train set:', X_train.shape,  y_train.shape)
print ('Test set:', X_test.shape,  y_test.shape)

"""Klsifikasi KNN"""

from sklearn.neighbors import KNeighborsClassifier

"""training data dengan k=1"""

k = 1
#Train Model and Predict  
neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)
neigh

"""Predicting"""

yhat = neigh.predict(X_test)
yhat[0:5]

"""Evaluasi Akurasi"""

from sklearn import metrics
print("Train set Accuracy: ", metrics.accuracy_score(y_train, neigh.predict(X_train)))
print("Test set Accuracy: ", metrics.accuracy_score(y_test, yhat))

"""Mencari nilai K optimum"""

Ks = 10
mean_acc = np.zeros((Ks-1))
std_acc = np.zeros((Ks-1))
ConfustionMx = [];
for n in range(1,Ks):
    
    #Train Model and Predict  
    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)
    yhat=neigh.predict(X_test)
    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)

    
    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])

mean_acc

plt.plot(range(1,Ks),mean_acc,'g')
plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)
plt.legend(('Accuracy ', '+/- 3xstd'))
plt.ylabel('Accuracy ')
plt.xlabel('Number of Nabors (K)')
plt.tight_layout()
plt.show()

print( "The best accuracy was with", mean_acc.max(), "with k=", mean_acc.argmax()+1)

"""Jacard Index Test"""

from sklearn.metrics import jaccard_similarity_score
jaccard_similarity_score(y_test, yhat)

"""F1 Score"""

from sklearn.metrics import f1_score
f1_score(y_test, yhat, average='weighted')

"""Confusion Matrix"""



def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
print(confusion_matrix(y_test, yhat, labels=[1,0]))

# Compute confusion matrix
cnf_matrix = confusion_matrix(y_test, yhat, labels=['Coffee & Tea','Breakfast''Smoothies & Shakes','Chicken & Fish','Beverages','Beef & Pork','Snacks & Sides','Desserts','Salads'])
np.set_printoptions(precision=2)

print (classification_report(y_test, yhat))

# Plot non-normalized confusion matrix
plt.figure(figsize=(10,10))
plot_confusion_matrix(cnf_matrix, classes=['Coffee & Tea','Breakfast''Smoothies & Shakes','Chicken & Fish','Beverages','Beef & Pork','Snacks & Sides','Desserts','Salads'],normalize= False,  title='Confusion matrix')

"""True Positif = 26

Cross validation Test
"""

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
kfold = KFold(n_splits=10, shuffle=True, random_state=0)

modelknn = KNeighborsClassifier(n_neighbors=5, weights='uniform')
scoring = 'accuracy'
scoreknn = cross_val_score(modelknn, X, y, cv=kfold, n_jobs=1, scoring=scoring)
print(scoreknn)

np.mean(scoreknn)

